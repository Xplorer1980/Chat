ChatGPT 4o Memoria piena Condividi 

Hunyuan2.0 è installabile in locale ma è gestibile con una sceda 
video AMD 6800 con 16 gb ? 

Sì, è possibile installare e utilizzare Hunyuan2.0 localmente su una scheda video AMD 6800 con 16 GB di 

VRAM. Sebbene le specifiche ufficiali indichino requisiti di memoria video molto elevati, la comunità ha 

sviluppato metodi per eseguire HunyuanVideo su GPU con meno memoria, inclusi modelli AMD. Ad 

esempio, un utente ha riportato di aver eseguito con successo HunyuanVideo su una AMD 6700XT con 

12 GB di VRAM, utilizzando ComfyUI su Ubuntu 22.04 con ROCm 6.3.0. Reddit 

Per ottimizzare le prestazioni su GPU con 16 GB di VRAM, è consigliabile utilizzare il tiling temporale, 

una tecnica che suddivide il video in segmenti temporali più piccoli, riducendo così l'uso complessivo 

della memoria video. Con l'aggiornamento a ComfyUI v0.3.10, è possibile eseguire il modello 

HunyuanVideo su GPU con soli 8 GB di VRAM, grazie al supporto del tiling temporale. 

ComfyUI Blog | Robin | Substack 

Per configurare correttamente il sistema, assicurati di installare ROCm, la piattaforma di calcolo aperta di 

AMD, che fornisce supporto per GPU AMD su Linux. AMD 

Per una guida dettagliata su come eseguire HunyuanVideo su una GPU AMD, puoi consultare il 

seguente tutorial video: 

Fonti 

anche per hunyuan3d ? 

Attualmente, Hunyuan3D 2.0 è progettato principalmente per funzionare su GPU NVIDIA con supporto 

CUDA. Le istruzioni di installazione e i requisiti di sistema indicano una preferenza per GPU NVIDIA, con 

menzione specifica dell'uso di toolkit CUDA e driver NVIDIA aggiornati. GitHub 

Tuttavia, non ci sono informazioni ufficiali riguardanti il supporto per GPU AMD, inclusa la AMD 6800 

con 16 GB di VRAM. Alcuni membri della comunità hanno riportato successi nell'esecuzione di modelli 

correlati su GPU AMD utilizzando framework come ROCm, ma tali implementazioni possono richiedere 

configurazioni avanzate e non sono garantite per funzionare con Hunyuan3D 2.0. Reddit 

Pertanto, sebbene sia teoricamente possibile eseguire Hunyuan3D 2.0 su una GPU AMD 6800 con 16 GB 

di VRAM, potrebbe essere necessario un lavoro di configurazione significativo e non è garantito il pieno 

supporto o le prestazioni ottimali. Si consiglia di consultare le risorse ufficiali e le comunità online per 

guide specifiche e supporto. 

Per una guida dettagliata sull'installazione locale di Hunyuan3D-2, puoi consultare il seguente video: 

Fonti 

alternative a hunyuan3d da far girare in locale con la 6800 a 16gb 
esistono senza dover impazzire nella configurazione? 

Attualmente, le alternative a Hunyuan3D che possono essere eseguite localmente su una GPU AMD RX 

6800 con 16 GB di VRAM sono limitate. La maggior parte dei modelli avanzati di intelligenza artificiale 

3D richiede configurazioni complesse e spesso sono ottimizzati per GPU NVIDIA con supporto CUDA. 

Tuttavia, la comunità open-source sta lavorando per migliorare il supporto per le GPU AMD. Ad 

esempio, ROCm (Radeon Open Compute) è una piattaforma di calcolo aperta sviluppata da AMD che 

mira a supportare l'esecuzione di applicazioni di deep learning su GPU AMD. Anche se ROCm è ancora 

in fase di sviluppo e potrebbe richiedere configurazioni avanzate, rappresenta una possibile soluzione 

per eseguire modelli 3D su hardware AMD. 

Un'altra opzione potrebbe essere l'utilizzo di framework di deep learning che offrono supporto per le 

GPU AMD, come TensorFlow con backend ROCm. Tuttavia, l'implementazione di questi framework può 

essere complessa e potrebbe non garantire le stesse prestazioni ottenute su hardware NVIDIA. 

In sintesi, mentre esistono alcune alternative, l'esecuzione locale di modelli 3D avanzati su una GPU 

AMD RX 6800 con 16 GB di VRAM potrebbe richiedere configurazioni tecniche significative e non 

garantisce prestazioni ottimali. Si consiglia di monitorare gli sviluppi nella comunità open-source e nelle 

piattaforme di calcolo per eventuali aggiornamenti che possano semplificare questo processo in futuro. 

Fonti 

2/2 

come andrebbe con una RTX 4070Ti Super o con una EVGA 
GeForce RTX 3090 Ti FTW3 BLACK GAMING, 24G-P5-4981-KR, 
24GB GDDR6X, iCX3, ARGB LED, Backplate, Free eLeash 

RTX 4070 Ti Super vs RTX 3090 Ti per l’uso con Hunyuan3D (e AI 3D in 

generale) 
Se il tuo obiettivo è eseguire Hunyuan3D o altri modelli AI 3D in locale senza complicazioni, entrambe 

le schede sono valide opzioni, ma hanno differenze importanti. 

1️⃣ RTX 4070 Ti Super 
VRAM : 16 GB GDDR6X 

CUDA Cores : ~8448 

Tensor Cores : 264 

Efficienza energetica : ⭐⭐⭐⭐⭐ 

Architettura : Ada Lovelace 

Supporto FP16, FP32 : Ottimo per AI 

Prezzo : Più economica della 3090 Ti 

Supporto software : Ottimo, driver aggiornati 

✅ PRO 

✔️ Più efficiente (consuma meno energia) 

✔️ Driver più ottimizzati per AI più recenti 

✔️ Supporta CUDA 12 e ultime ottimizzazioni di NVIDIA 

✔️ Costo inferiore rispetto alla 3090 Ti 

❌ CONTRO 

❌ Meno VRAM (16GB) : Se usi modelli molto pesanti, potresti avere problemi rispetto ai 24GB della 

3090 Ti. 

❌ Se i modelli di AI 3D richiedono molta memoria , potrebbe saturarsi prima della 3090 Ti. 

2️⃣ RTX 3090 Ti (EVGA FTW3 BLACK GAMING) 
VRAM : 24 GB GDDR6X 

CUDA Cores : 10752 

Tensor Cores : 336 

Efficienza energetica : ⭐⭐ (assorbe molta corrente) 

Architettura : Ampere 

Supporto FP16, FP32 : Ottimo per AI 

Prezzo : Più cara della 4070 Ti Super 

Supporto software : Ottimo, anche se leggermente meno ottimizzata rispetto alla serie 4000 

✅ PRO 

✔️ Più VRAM (24GB) : Perfetta per AI con modelli molto pesanti 

✔️ Più CUDA Cores e Tensor Cores : Performance elevate 

✔️ Supporta anche modelli AI più vecchi che potrebbero non essere ottimizzati per la serie 4000 

❌ CONTRO 

❌ Consuma MOLTA più energia (450W vs ~285W della 4070 Ti Super) 

❌ Più calda e ingombrante 

❌ Driver meno ottimizzati per le ultime AI 

Quale scegliere per AI 3D e Hunyuan3D? 
Se vuoi il miglior compromesso tra prezzo, potenza ed efficienza → RTX 4070 Ti Super 

Se vuoi il massimo della VRAM per modelli pesanti e non ti preoccupa il consumo → RTX 3090 Ti 

Se l’uso principale è Hunyuan3D e AI 3D generativa , probabilmente la 4070 Ti Super è la scelta 

migliore. 

Se invece vuoi lavorare con modelli AI molto grandi senza compromessi → 3090 Ti . 

in assoluto quale scheda sarebbe ottimale anche in rapporto al 

prezzo che posso trovare sia nuovo che usato sopratutto per Ai 
generativa 2d e Ai generativa 3d 

Per determinare la scheda grafica ottimale per l' IA generativa 2D e 3D , considerando il rapporto tra 

prestazioni e prezzo, è importante valutare sia le esigenze specifiche dei tuoi progetti che il budget 

disponibile. Le GPU NVIDIA sono generalmente preferite per applicazioni di intelligenza artificiale grazie 

al loro supporto avanzato per CUDA e alle librerie ottimizzate per il deep learning. 

Ecco alcune opzioni da considerare: 

NVIDIA GeForce RTX 4070 Ti 

Offre un buon equilibrio tra prestazioni e prezzo, con 12 GB di memoria GDDR6X. Ideale per 
progetti di IA generativa di media complessità. 

NVIDIA GeForce RTX 4080 Super 
Con 16 GB di memoria, è adatta per applicazioni più esigenti in termini di calcolo e memoria. Offre 
prestazioni elevate per carichi di lavoro complessi. 

NVIDIA GeForce RTX 4090 
Dotata di 24 GB di memoria GDDR6X, rappresenta una delle migliori opzioni per applicazioni di IA 

generativa avanzata, sebbene a un prezzo più elevato. 

NVIDIA GeForce RTX 3090 
Con 24 GB di memoria, offre prestazioni eccellenti ed è spesso disponibile a prezzi competitivi nel 

mercato dell'usato. 

NVIDIA GeForce RTX 3080 
Con 10 GB di memoria, è una scelta valida per progetti meno esigenti, offrendo un buon rapporto 
qualità-prezzo. 

Per quanto riguarda le opzioni usate , le serie RTX 3080 e RTX 3090 possono offrire un valore 

significativo, ma è fondamentale verificare le condizioni della scheda e la presenza di eventuali garanzie 

residue. 

Inoltre, NVIDIA ha recentemente annunciato la serie RTX 50, che introduce miglioramenti significativi in 

termini di prestazioni e efficienza energetica. Tuttavia, essendo una novità, i prezzi potrebbero essere 

elevati e la disponibilità limitata. Polygon 

In sintesi, la scelta della GPU ideale dipende dalle specifiche esigenze dei tuoi progetti di IA generativa e 

dal budget a tua disposizione. Le opzioni elencate sopra rappresentano un buon punto di partenza per 

trovare il giusto equilibrio tra prestazioni e costo. 

Fonti